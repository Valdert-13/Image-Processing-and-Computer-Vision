{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Neural network for recognizing human actions on the KTH dataset.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"y7c-vhTto-1_","colab_type":"text"},"source":["# Обработка видео\n","Классификация действий по видео\n"]},{"cell_type":"markdown","metadata":{"id":"JH2ri2mQTU5s","colab_type":"text"},"source":["## Переключение версии TensorFlow"]},{"cell_type":"code","metadata":{"id":"cqhfvqRrugoS","colab_type":"code","colab":{}},"source":["#%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iv4yU3Gb4MlY","colab_type":"code","colab":{}},"source":["import os\n","import glob\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEbPbpjIDV57","colab_type":"code","outputId":"ccef03d1-c9f4-4b79-d5bf-25121198c6f9","executionInfo":{"status":"ok","timestamp":1591374735599,"user_tz":-180,"elapsed":781,"user":{"displayName":"Румянцев Кирилл","photoUrl":"","userId":"08642037802757655753"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["if 1:\n","    !pip install scikit-video==1.1.11\n","import skvideo\n","print(skvideo.__file__)\n","import skvideo.io"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scikit-video==1.1.11 in d:\\anaconda3\\envs\\cnn\\lib\\site-packages (1.1.11)\n","Requirement already satisfied: scipy in d:\\anaconda3\\envs\\cnn\\lib\\site-packages (from scikit-video==1.1.11) (1.4.1)\n","Requirement already satisfied: pillow in d:\\anaconda3\\envs\\cnn\\lib\\site-packages (from scikit-video==1.1.11) (7.1.2)\n","Requirement already satisfied: numpy in d:\\anaconda3\\envs\\cnn\\lib\\site-packages (from scikit-video==1.1.11) (1.18.1)\n","d:\\anaconda3\\envs\\cnn\\lib\\site-packages\\skvideo\\__init__.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z9xxQH9LTsll","colab_type":"text"},"source":["## Подготовка датасета для классификации"]},{"cell_type":"code","metadata":{"id":"xXx10w4T7JcT","colab_type":"code","outputId":"3a6af0f2-fcc4-45e4-9608-790522a69ffc","executionInfo":{"status":"ok","timestamp":1591374477357,"user_tz":-180,"elapsed":26,"user":{"displayName":"Румянцев Кирилл","photoUrl":"","userId":"08642037802757655753"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["classes = [\n","    'walking',\n","    'jogging',\n","    'running',\n","    'boxing',\n","    'handwaving',\n","    'handclapping',\n","]\n","\n","data_list = []\n","data_root = 'G:/data/KTH/'\n","for cls in classes:\n","    print('Processing class: {}'.format(cls))\n","    for fpath in glob.glob(os.path.join(data_root, cls, '*.avi')):\n","        cls_idx = classes.index(cls)\n","        data_list.append((fpath, cls_idx))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Processing class: walking\n","Processing class: jogging\n","Processing class: running\n","Processing class: boxing\n","Processing class: handwaving\n","Processing class: handclapping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WLl1FYXmLg9u","colab_type":"code","colab":{}},"source":["SUBSET_LEN = 400 # Количество пар для обучения\n","MAX_FRAMES = 600\n","BATCH_SIZE = 8\n","NUM_EPOCHS = 10\n","LEARNING_RATE = 0.0001"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYO8E2UILVtv","colab_type":"code","colab":{}},"source":["class CreatingDataset():\n","\n","  \"\"\"Клас создания датасета\"\"\"\n","\n","  def __init__(self,data_list=data_list, MAX_FRAMES=MAX_FRAMES, SUBSET_LEN=SUBSET_LEN, BATCH_SIZE=BATCH_SIZE, NUM_EPOCHS=NUM_EPOCHS):        \n","      self.data_list = data_list \n","      self.MAX_FRAMES = MAX_FRAMES\n","      self.SUBSET_LEN = SUBSET_LEN\n","      self.BATCH_SIZE = BATCH_SIZE\n","      self.NUM_EPOCHS = NUM_EPOCHS\n","\n","  def split_dataset(self, data_list, SUBSET_LEN):\n","    \"\"\"Создание пар для обучения и разделение датасета на тестовый и тренировачный\"\"\"\n","    random.shuffle(data_list)\n","    data_array = np.array(data_list)\n","    train_x, valid_x, train_y, valid_y = train_test_split(data_array[:, 0],\n","                                                          data_array[:, 1],\n","                                                          train_size=SUBSET_LEN, random_state=21,\n","                                                          stratify=data_array[:, 1])\n","\n","    assert SUBSET_LEN == len(train_x)\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n","    test_dataset = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n","\n","    return dataset, test_dataset\n","\n","  def dataset_processing(self, dataset, SUBSET_LEN, BATCH_SIZE):\n","    \"\"\"обработка датасета\"\"\"\n","\n","\n","\n","    def fpath_to_video(fpath):\n","        fpath = fpath.numpy().decode('utf-8')\n","        videodata = skvideo.io.vread(fpath)\n","        videodata = videodata.astype(np.float32) / 255.\n","\n","        tmp = videodata.copy()\n","        # если количество кадров в видео меньше максимального\n","        if videodata.shape[0] < MAX_FRAMES:\n","          # то определяем сколко раз надо повторить операцию vstack\n","          num_iter = round(MAX_FRAMES / videodata.shape[0]) + 1\n","          # создаем временный файл, в котором будем хранить повторы\n","          tmp = videodata.copy()\n","          # стакаем необходимое количество раз\n","          for iterations in range(num_iter):\n","            tmp = np.vstack((tmp, videodata))\n","            if tmp.shape[0] > MAX_FRAMES:\n","              break\n","          # так как мы повторяли ролик сам в себя несколько раз, то его длина может быть больше чем необходимая\n","          # поэтому возьмем только необходимое нам количество кадров\n","        tmp = tmp[:MAX_FRAMES, ...]\n","        \n","        return tmp\n","\n","    dataset = dataset.map(lambda fpath, label: (tf.py_function(fpath_to_video, [fpath], Tout=tf.float32),\n","                                                tf.numpy_function(np.int8, [label], tf.int8)))\n","    # dataset = dataset.shuffle(buffer_size=SUBSET_LEN)\n","    # dataset = dataset.batch(BATCH_SIZE)\n","\n","    return dataset\n","\n","  def bilder_dataset(self,data_list=data_list, MAX_FRAMES=MAX_FRAMES, SUBSET_LEN=SUBSET_LEN, BATCH_SIZE=BATCH_SIZE, NUM_EPOCHS=NUM_EPOCHS):\n","    \"\"\"Сборка доатасета\"\"\"\n","    dataset, test_dataset = self.split_dataset(data_list, SUBSET_LEN)\n","    dataset = self.dataset_processing(dataset, SUBSET_LEN, BATCH_SIZE)\n","    test_dataset = self.dataset_processing(test_dataset, SUBSET_LEN, BATCH_SIZE)\n","\n","    return dataset, test_dataset\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7seL-iH1ggzq","colab_type":"code","colab":{}},"source":["CD = CreatingDataset()\n","dataset, test_dataset = CD.bilder_dataset(data_list, MAX_FRAMES, SUBSET_LEN, BATCH_SIZE, NUM_EPOCHS)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WMuN7QibUPJa","colab_type":"text"},"source":["## Создание модели CNN"]},{"cell_type":"code","metadata":{"id":"-IbbBxRa3ue4","colab_type":"code","colab":{}},"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Conv3D(32, (5, 5, 5), (1, 2, 2), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPool3D((1, 2, 2), padding='same'),\n","    tf.keras.layers.Conv3D(64, (5, 5, 5), (1, 2, 2), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPool3D((1, 2, 2), padding='same'),\n","    tf.keras.layers.Conv3D(64, (3, 3, 3), (1, 2, 2), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPool3D((1, 2, 2), padding='same'),\n","    tf.keras.layers.Conv3D(64, (3, 3, 3), (1, 1, 1), padding='same', activation=None),\n","    tf.keras.layers.GlobalAveragePooling3D(),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(6, activation=None),\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRR7KDG_UTqW","colab_type":"text"},"source":["## Подготовка к обучению"]},{"cell_type":"code","metadata":{"id":"R_IRN1KLu8YC","colab_type":"code","colab":{}},"source":["model.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","    optimizer=tf.keras.optimizers.Adam(LEARNING_RATE))\n","\n","writer = tf.summary.create_file_writer('logs/exp1')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vdXWGrAMUYiK","colab_type":"text"},"source":["## Цикл обучения модели"]},{"cell_type":"code","metadata":{"id":"D9oDlO9TYNBe","colab_type":"code","outputId":"9f214120-65c4-4df0-dd47-467dca3cfccf","executionInfo":{"status":"ok","timestamp":1591374247427,"user_tz":-180,"elapsed":80,"user":{"displayName":"Румянцев Кирилл","photoUrl":"","userId":"08642037802757655753"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","global_step = 0\n","losses = []\n","for ep in range(NUM_EPOCHS):\n","    for i, (videodata, labels) in enumerate(dataset):\n","        loss_value = model.train_on_batch(videodata, labels)\n","\n","        if i % 10 == 0:\n","            print(f'[{ep}/{NUM_EPOCHS}][{i}/{SUBSET_LEN}] Loss: {loss_value}')\n","            losses.append([loss_value, global_step])\n","               \n","        global_step += 1"],"execution_count":0,"outputs":[{"output_type":"error","ename":"UnknownError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   1896\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1897\u001b[1;33m     \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1898\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2478\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2479\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2480\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n","\u001b[1;31mUnknownError\u001b[0m: AssertionError: Cannot find installation of real FFmpeg (which comes with ffprobe).\nTraceback (most recent call last):\n\n  File \"d:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 234, in __call__\n    return func(device, token, args)\n\n  File \"d:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 123, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-6-f65adf9a0386>\", line 35, in fpath_to_video\n    videodata = skvideo.io.vread(fpath)\n\n  File \"d:\\anaconda3\\envs\\cnn\\lib\\site-packages\\skvideo\\io\\io.py\", line 133, in vread\n    assert _HAS_FFMPEG, \"Cannot find installation of real FFmpeg (which comes with ffprobe).\"\n\nAssertionError: Cannot find installation of real FFmpeg (which comes with ffprobe).\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   1898\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1900\u001b[1;33m     \u001b[0mexecutor_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32md:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\executor.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mUnknownError\u001b[0m: AssertionError: Cannot find installation of real FFmpeg (which comes with ffprobe).\nTraceback (most recent call last):\n\n  File \"d:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 234, in __call__\n    return func(device, token, args)\n\n  File \"d:\\anaconda3\\envs\\cnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 123, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-6-f65adf9a0386>\", line 35, in fpath_to_video\n    videodata = skvideo.io.vread(fpath)\n\n  File \"d:\\anaconda3\\envs\\cnn\\lib\\site-packages\\skvideo\\io\\io.py\", line 133, in vread\n    assert _HAS_FFMPEG, \"Cannot find installation of real FFmpeg (which comes with ffprobe).\"\n\nAssertionError: Cannot find installation of real FFmpeg (which comes with ffprobe).\n\n\n\t [[{{node EagerPyFunc}}]]"]}]},{"cell_type":"markdown","metadata":{"id":"fsq2P31vUck6","colab_type":"text"},"source":["## TensorBoard"]},{"cell_type":"code","metadata":{"id":"s0314NhOrkik","colab_type":"code","colab":{}},"source":["%load_ext tensorboard\n","%tensorboard --logdir logs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbveCKhEtKLK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}